# =============================================================================
# Backend Configuration
# =============================================================================

# FERNET_KEY: Encryption key for API keys (REQUIRED)
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
FERNET_KEY=

# DATABASE_URL: SQLite database path
DATABASE_URL=sqlite+aiosqlite:///./merlin.db

# OPTILLM_URL: URL of the OptiLLM proxy service
OPTILLM_URL=http://localhost:8000

# CORS_ORIGINS: Allowed origins for CORS (comma-separated)
CORS_ORIGINS=http://localhost:3000

# LOG_LEVEL: Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# OptiLLM Configuration
# =============================================================================

# OPTILLM_BASE_URL: Base URL for the LLM provider
# Change to your preferred provider (OpenAI, Anthropic, etc.)
OPTILLM_BASE_URL=https://api.openai.com/v1

# OPTILLM_APPROACH: Default optimization approach
OPTILLM_APPROACH=auto

# OPTILLM_API_KEY: Optional API key for securing the OptiLLM proxy itself
# Leave empty if you don't want to add an extra auth layer on the proxy
OPTILLM_API_KEY=

# =============================================================================
# Frontend Configuration
# =============================================================================

# NEXT_PUBLIC_API_URL: Backend API URL (visible to browser)
NEXT_PUBLIC_API_URL=http://localhost:8001
