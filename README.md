# Merlin - Agentic AI Workbench

A **2-pillar BYOK (Bring-Your-Own-Key) AI platform** that supercharges LLMs with advanced inference techniques and agentic workflows.

## ğŸ¯ What is Merlin?

Merlin is a production-ready AI workbench with:

1. **Performance Hub** - Chat interface with integrated OptiLLM optimization (10+ techniques)
2. **Agentic Workflow Engine** - Multi-step workflows with approval gates and external tool integration

**Key Differentiator**: Not another ChatGPT clone. Merlin demonstrates advanced AI engineering with workflow orchestration, external API integration, and inference optimization directly integrated into the backend.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MERLIN AI WORKBENCH                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  Pillar 1: Performance Hub                                       â”‚
â”‚  â”œâ”€ Next.js 15 Frontend (SSE streaming, session management)     â”‚
â”‚  â”œâ”€ FastAPI Backend (encrypted keys, chat API, rate limiting)   â”‚
â”‚  â””â”€ Integrated OptiLLM (inference optimization, direct calls)   â”‚
â”‚                                                                   â”‚
â”‚  Pillar 2: Agentic Workflow Engine                              â”‚
â”‚  â”œâ”€ Workflow Orchestrator (6 step types, approval gates)        â”‚
â”‚  â”œâ”€ External APIs (GPTZero, Undetectable AI)                    â”‚
â”‚  â””â”€ Essay Writer Template (plan â†’ draft â†’ humanize â†’ detect)    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Technology Stack

- **Frontend**: Next.js 15 (App Router), React 18, TypeScript, Tailwind CSS, Zustand
- **Backend**: FastAPI, SQLAlchemy, Pydantic, Cryptography (Fernet), slowapi (rate limiting)
- **AI Inference**: OptiLLM (integrated, direct function calls - no proxy server)
- **External APIs**: GPTZero (AI detection), Undetectable AI (humanization)
- **Database**: SQLite (upgradable to PostgreSQL for production)
- **Infrastructure**: Docker, Docker Compose, Render (free tier), Vercel

## Features

### Performance Hub (Chat Interface)
- ğŸ” **BYOK Management**: Securely store API keys for OpenAI, Anthropic, Google with Fernet encryption
- ğŸ’¬ **Multi-Model Chat**: Real-time streaming with GPT-4o, Claude 3.5, Gemini 2.5
- âš¡ **OptiLLM Techniques**: Directly integrated (MOA, CoT Reflection, PlanSearch, etc.)
- ğŸ’¾ **Chat Sessions**: Organize conversations, auto-save, load history
- ğŸ¨ **Landing Page**: DeepSeek-inspired marketing homepage with product showcase
- â±ï¸ **Rate Limiting**: 30 requests/hour per user (aligned with Neon Free Tier)
- ğŸ”„ **Retry Mechanism**: Inline retry button for failed messages
- âš™ï¸ **Server Wake Detection**: Handles Render cold starts gracefully (60s timeout)

### Agentic Workflow Engine
- ğŸ¤– **6 Step Types**: PLAN, DRAFT, VERIFY, HUMANIZE, INTEGRITY_CHECK, AI_DETECTION
- âœ… **Approval Gates**: Pause at each step for user review
- ğŸ”„ **State Persistence**: Resume workflows after interruption
- ğŸ¯ **Multi-Model Orchestration**: Different models per step
- ğŸ› ï¸ **External Tool Integration**: GPTZero for AI detection, Undetectable AI for humanization
- ğŸ“ **Essay Writer Template**: Complete 6-step workflow ready to use

### Production-Ready
- ğŸ”’ **Fernet Encryption**: AES-128-CBC for API keys at rest
- ğŸŒ **CORS Protection**: Configurable allowed origins
- ğŸ“Š **Rate Limiting**: Per-user rate limits with slowapi
- ğŸ§ª **Comprehensive Testing**: Backend tests with pytest, fixtures, mocking
- ğŸ“¦ **Docker Support**: Multi-container setup with docker-compose
- ğŸš€ **Free Tier Optimized**: Deployed on Render free tier with cost-conscious limits

## Prerequisites

- Node.js 20+ and npm
- Python 3.11+
- Docker and Docker Compose (optional)
- Git

## Quick Start

### 1. Clone the repository

```bash
git clone <repository-url>
cd merlin
```
### 2. Configure environment variables

```bash
# Copy the example environment file
cp .env.example .env

# Generate a Fernet key for encryption
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# Edit .env and add your generated FERNET_KEY
```

### 3. Run with Docker Compose

```bash
docker-compose up --build
```

The application will be available at:
- Frontend: http://localhost:3000
- Backend: http://localhost:8001

### 4. Development Setup (without Docker)

**Backend (with integrated OptiLLM):**
```bash
cd backend
pip install -e .
fastapi dev src/merlin/main.py --port 8001
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev
```

Note: OptiLLM is now directly integrated into the FastAPI backend - no separate proxy server needed!

## Project Structure

```
merlin/
â”œâ”€â”€ frontend/               # Next.js 15 application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # App Router pages
â”‚   â”‚   â”‚   â”œâ”€â”€ (chat)/    # Chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ (settings)/ # Settings pages
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx   # Landing page
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â””â”€â”€ lib/           # Utilities and state
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/               # FastAPI application
â”‚   â”œâ”€â”€ src/merlin/
â”‚   â”‚   â”œâ”€â”€ api/          # API routes
â”‚   â”‚   â”œâ”€â”€ core/         # Config and security
â”‚   â”‚   â”œâ”€â”€ db/           # Database models
â”‚   â”‚   â”œâ”€â”€ optillm/      # Integrated OptiLLM techniques
â”‚   â”‚   â”œâ”€â”€ repositories/ # Data access layer
â”‚   â”‚   â”œâ”€â”€ services/     # Business logic (including OptiLLMService)
â”‚   â”‚   â””â”€â”€ main.py       # FastAPI app entry
â”‚   â”‚   â””â”€â”€ schemas/      # Pydantic models
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ docker-compose.yml     # Orchestration
â””â”€â”€ README.md
```

## Security Notes

- API keys are encrypted at rest using Fernet (AES-128-CBC + HMAC-SHA256)
- Encryption key (`FERNET_KEY`) must be securely generated and stored
- Never commit `.env` files or expose the `FERNET_KEY`
- Keys are validated before storage by making test API calls
- Database file (`merlin.db`) contains encrypted keys - protect it accordingly

## Development Workflow

1. **Frontend Development**: `cd frontend && npm run dev` (hot reload on http://localhost:3000)
2. **Backend Development**: `cd backend && fastapi dev src/merlin/main.py` (hot reload on http://localhost:8001)
3. **Type Checking**: `npm run type-check` (frontend), `mypy src` (backend)
4. **Linting**: `npm run lint` (frontend), `ruff check src` (backend)
5. **Testing**: `npm test` (frontend), `pytest` (backend)

## OptiLLM Techniques

## OptiLLM Techniques

Merlin supports 20+ optimization techniques via OptiLLM:

- **PlanSearch**: Complex problem-solving with planning
- **CoT-Reflection**: Chain-of-thought with self-reflection
- **Mixture of Agents (MoA)**: Multi-agent collaboration
- **Self-Consistency**: Sample multiple reasoning paths
- **LEAP**: Learning to reason via latent exploration
- **R-STAR**: Recursive self-training for reasoning

Enable techniques in the chat interface (Advanced Settings panel) to optimize inference quality and cost.

## Workflow Example: Essay Writer

```bash
# 1. Create workflow from template
POST /api/v1/workflows/templates/essay-writer
{
    "goal": "Write a 1000-word essay on the American Revolution",
    "word_count": 1000,
    "style": "academic"
}

# 2. Execute workflow (6 steps with approval gates)
POST /api/v1/workflows/{workflow_id}/execute

# Steps execute sequentially:
# â†’ PLAN: Create outline (plansearch technique)
# â†’ DRAFT: Write full essay (Claude, cot_reflection)
# â†’ VERIFY: Check requirements (GPT-4o)
# â†’ HUMANIZE: Undetectable AI humanization
# â†’ INTEGRITY_CHECK: Verify content preservation
# â†’ AI_DETECTION: GPTZero detection score

# 3. Approve each step
POST /api/v1/workflows/{workflow_id}/steps/{step_index}/approve
{"approved": true, "feedback": "Looks great!"}
```

## Documentation

- **[TESTING.md](./TESTING.md)** - Comprehensive testing guide
- **[DEPLOYMENT.md](./DEPLOYMENT.md)** - Free deployment options (Render, Railway, Vercel)
- **[EXTERNAL_APIS.md](./EXTERNAL_APIS.md)** - GPTZero and Undetectable AI integration
- **[IMPLEMENTATION_SUMMARY.md](./IMPLEMENTATION_SUMMARY.md)** - Complete feature overview

## External API Integration

Merlin integrates with:

- **GPTZero** - AI text detection for AI_DETECTION workflow steps
- **Undetectable AI** - Text humanization for HUMANIZE workflow steps

See `EXTERNAL_APIS.md` for setup instructions and API details.

## Future Roadmap

- [x] ~~Agentic Workflow Engine~~ âœ… Complete
- [x] ~~External API Integration~~ âœ… Complete
- [x] ~~Essay Writer Template~~ âœ… Complete
- [ ] Workflow Frontend UI (visual stepper, diff viewer)
- [ ] Speculative Decoding for 2-3x faster inference
- [ ] Multi-user support with authentication
- [ ] PostgreSQL migration for production
- [ ] Rate limiting and cost tracking
- [ ] Custom workflow templates (user-created)

## License

MIT

## Contributing

Contributions are welcome! Please:

1. Follow code style (Black for Python, Prettier for TypeScript)
3. Add tests for new features
4. Open an issue or submit a pull request

## Support

- **Documentation**: See docs in repository
- **API Reference**: http://localhost:8001/docs (FastAPI auto-docs)
- **Issues**: GitHub Issues for bugs/features

---

**Built to showcase AI Engineering depth beyond simple ChatGPT clones.**
